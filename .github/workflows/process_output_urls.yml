name: Archive URLs to Wayback Machine (Parallel Processing)
on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:

jobs:
  prepare:
    runs-on: ubuntu-latest
    outputs:
      total_urls: ${{ steps.split.outputs.total_urls }}
    steps:
      - uses: actions/checkout@v4
      
      - id: split
        name: Split URLs file
        run: |
          if [ ! -f output_urls.txt ]; then
            echo "output_urls.txt not found"
            exit 1
          fi
          
          total_urls=$(wc -l < output_urls.txt)
          echo "total_urls=$total_urls" >> $GITHUB_OUTPUT
          
          # Calculate URLs per job (rounded up)
          urls_per_job=$(( (total_urls + 19) / 20 ))
          echo "Splitting into chunks of $urls_per_job URLs"
          
          mkdir -p splits 2>/dev/null
          split -l "$urls_per_job" output_urls.txt splits/batch_
          
          echo "Created splits:"
          ls -l splits/

          git config --local user.email "action@github.com" >/dev/null 2>&1
          git config --local user.name "GitHub Action" >/dev/null 2>&1
          git add splits/ >/dev/null 2>&1
          git commit -m "Create URL batches" >/dev/null 2>&1 || true
          git push >/dev/null 2>&1

  archive:
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      matrix:
        job_id: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
      max-parallel: 20
      fail-fast: false
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Process URL batch
        env:
          JOB_ID: ${{ matrix.job_id }}
          TOTAL_URLS: ${{ needs.prepare.outputs.total_urls }}
        run: |
          # Use a more reliable way to get the batch file
          readarray -t batch_files < <(ls -v splits/batch_* 2>/dev/null)
          job_index=$((JOB_ID - 1))
          
          if [ $job_index -lt ${#batch_files[@]} ]; then
            batch_file="${batch_files[$job_index]}"
            echo "Job ${JOB_ID} processing: $batch_file"
            
            while IFS= read -r url; do
              if [ ! -z "$url" ]; then
                echo "Processing: $url"
                curl -s -X POST "https://web.archive.org/save/$url" >/dev/null 2>&1
                sleep 5
              fi
            done < "$batch_file"
            
            rm "$batch_file" 2>/dev/null
            
            git config --local user.email "action@github.com" >/dev/null 2>&1
            git config --local user.name "GitHub Action" >/dev/null 2>&1
            
            retry_count=0
            while [ $retry_count -lt 10 ]; do
              if [ $retry_count -gt 0 ]; then
                git pull --rebase origin main >/dev/null 2>&1
              fi
              
              git add -u >/dev/null 2>&1
              if git commit -m "Process batch ${JOB_ID}" >/dev/null 2>&1 && git push >/dev/null 2>&1; then
                echo "Batch ${JOB_ID} complete"
                exit 0
              fi
              
              retry_count=$((retry_count + 1))
              [ $retry_count -lt 10 ] && sleep $((retry_count * 5))
            done
          else
            echo "No work for job ${JOB_ID}"
            exit 0
          fi

  cleanup:
    needs: [archive]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Cleanup and consolidate
        run: |
          remaining_urls=""
          if [ -d "splits" ]; then
            for batch in splits/batch_*; do
              [ -f "$batch" ] && remaining_urls="$remaining_urls$(cat $batch)\n"
            done
          fi
          
          echo -e "$remaining_urls" > output_urls.txt
          rm -rf splits/ 2>/dev/null
          date > last_archive.txt
          
          git config --local user.email "action@github.com" >/dev/null 2>&1
          git config --local user.name "GitHub Action" >/dev/null 2>&1
          
          retry_count=0
          while [ $retry_count -lt 10 ]; do
            if [ $retry_count -gt 0 ]; then
              git pull --rebase origin main >/dev/null 2>&1
            fi
            
            git add -A >/dev/null 2>&1
            if git commit -m "Cleanup remaining URLs" >/dev/null 2>&1 && git push >/dev/null 2>&1; then
              echo "Cleanup complete"
              exit 0
            fi
            
            retry_count=$((retry_count + 1))
            [ $retry_count -lt 10 ] && sleep $((retry_count * 5))
          done
