name: scrape
on:
  workflow_dispatch:  # Allows manual triggering
  #schedule:
  #  - cron: '0 * * * *'  # Runs every hour
  # disabled because currently the version that checks for 404 is being used instead

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 fake-useragent
    - name: Run URL scraper
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: python scraper.py
    - name: Commit and push if changed
      run: |
        git config --global user.name 'GitHub Action'
        git config --global user.email 'action@github.com'
        git add .
        git diff --quiet && git diff --staged --quiet || (git commit -m "Update scraped URLs"; git push)
