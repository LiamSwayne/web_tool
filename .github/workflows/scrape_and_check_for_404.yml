name: scrape and check for 404
on:
  workflow_dispatch:  # Allows manual triggering
  schedule:
    - cron: '0 */12 * * *'  # Runs every 12 hours
  push:
    branches:
      - main
    paths:
      - 'source_urls.txt'

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 fake-useragent
    - name: Run URL scraper
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: python scrape_and_check_for_404.py
    - name: Commit and push if changed
      run: |
        git config --global user.name 'GitHub Action'
        git config --global user.email 'action@github.com'
        git add .
        git diff --quiet && git diff --staged --quiet || (git commit -m "ðŸ¤– Update scraped URLs"; git push)
